{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20de7281",
   "metadata": {},
   "source": [
    "# **Movie Perdictions Part 2A**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40180c8d",
   "metadata": {},
   "source": [
    "**Name:** **Derek Overton**\n",
    "\n",
    "**Date:** **2/19/2023**\n",
    "\n",
    "**Project:** **Movie Predictions Part 2A**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbc8e7",
   "metadata": {},
   "source": [
    "## **Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c60d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "\n",
    "# Additional Imports\n",
    "import os, json, math, time\n",
    "import tmdbsimple as tmdb\n",
    "from tqdm.notebook import tqdm_notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df4e1016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\talen\\anaconda3\\envs\\dojo-env\\lib\\site-packages (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\talen\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from tqdm) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "# Install tmdbsimple (only need to run once)\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df87d9f6",
   "metadata": {},
   "source": [
    "# **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc191407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Basics\n",
    "basics = pd.read_csv('Data/basics.csv.gz', sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beba8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Ratings:\n",
    "ratings = pd.read_csv('https://datasets.imdbws.com/title.ratings.tsv.gz', sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18aeb1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Akas:\n",
    "akas = pd.read_csv('https://datasets.imdbws.com/title.akas.tsv.gz', sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29237db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['api-key'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load API Credentials\n",
    "with open('/Users/talen/.secret/tmbd_api.json') as f:   #use your path here!\n",
    "    login = json.load(f)\n",
    "##Display the keys of the loaded dictionary \n",
    "login.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61a433fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb.API_KEY =  login['api-key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81036bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ddc30d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_with_rating(movie_id):\n",
    "    \"\"\" Adapted from source github/celuao/tmdbsimple\"\"\"\n",
    "    #Get the movie object for the current id\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "\n",
    "    # Save the .info .releases dictionaries\n",
    "    info = movie.info()\n",
    "    releases = movie.releases()\n",
    "\n",
    "    # Loop through countries in releases\n",
    "    for c in releases['countries']:\n",
    "        # if the country abbreviation == US\n",
    "        if c['iso_3166_1'] == 'US':\n",
    "            # save a 'certification' key in info with the certification\n",
    "            info['certification'] = c['certification']\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc6ba654",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/tmdb_api_results_2000.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load JSON file into pandas dataframe\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData/tmdb_api_results_2000.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/tmdb_api_results_2000.json'"
     ]
    }
   ],
   "source": [
    "# Load JSON file into pandas dataframe\n",
    "with open('Data/tmdb_api_results_2000.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "df = pd.json_normalize(data)\n",
    "\n",
    "# Save dataframe as compressed CSV file\n",
    "with gzip.open('Data/tmdb_api_results_2000.csv.gz', 'wt', encoding='utf8') as file:\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3e2fec",
   "metadata": {},
   "source": [
    "# **Custom Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c31f22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'akas.csv.gz', 'basics.csv.gz', 'ratings.csv.gz']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for DATA folder\n",
    "FOLDER = \"Data/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc03e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Movie With Rating\n",
    "def get_movie_with_rating(movie_id):\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    \n",
    "    info = movie.info()\n",
    "    \n",
    "    releases = movie.releases()\n",
    "    \n",
    "    for c in releases['countries']:\n",
    "        if c['iso_3166_1']=='US':\n",
    "            info['certification']=c['certification']\n",
    "    return info     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a755d49",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIKeyError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIKeyError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#test get_movie... function with Avengers \"tt0848228\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mget_movie_with_rating\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtt0848228\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m      3\u001b[0m test\n",
      "Cell \u001b[1;32mIn [19], line 5\u001b[0m, in \u001b[0;36mget_movie_with_rating\u001b[1;34m(movie_id)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_movie_with_rating\u001b[39m(movie_id):\n\u001b[0;32m      3\u001b[0m     movie \u001b[38;5;241m=\u001b[39m tmdb\u001b[38;5;241m.\u001b[39mMovies(movie_id)\n\u001b[1;32m----> 5\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[43mmovie\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     releases \u001b[38;5;241m=\u001b[39m movie\u001b[38;5;241m.\u001b[39mreleases()\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m releases[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountries\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\tmdbsimple\\movies.py:73\u001b[0m, in \u001b[0;36mMovies.info\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03mGet the primary information about a movie.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    A dict representation of the JSON returned from the API.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     71\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_id_path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 73\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GET\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_attrs_to_values(response)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\tmdbsimple\\base.py:110\u001b[0m, in \u001b[0;36mTMDB._GET\u001b[1;34m(self, path, params)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_GET\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\tmdbsimple\\base.py:83\u001b[0m, in \u001b[0;36mTMDB._request\u001b[1;34m(self, method, path, params, payload)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, path, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, payload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     82\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_complete_url(path)\n\u001b[1;32m---> 83\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# Create a new request session if no global session is defined\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\tmdbsimple\\base.py:68\u001b[0m, in \u001b[0;36mTMDB._get_params\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m API_KEY\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m API_KEY:\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIKeyError\n\u001b[0;32m     70\u001b[0m api_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_key\u001b[39m\u001b[38;5;124m'\u001b[39m: API_KEY}\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m params:\n",
      "\u001b[1;31mAPIKeyError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#test get_movie... function with Avengers \"tt0848228\"\n",
    "test = get_movie_with_rating(\"tt0848228\") \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc308d",
   "metadata": {},
   "source": [
    "## **Write Json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bf13a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba568adb",
   "metadata": {},
   "source": [
    "# **Create Required Lists for the LOOP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8a997d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an error list\n",
    "errors = [ ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb6fde",
   "metadata": {},
   "source": [
    "# *Write JSON Data to CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7948db32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm_notebook' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Start of OUTER loop\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m YEAR \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm_notebook\u001b[49m(YEARS_TO_GET, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYEARS\u001b[39m\u001b[38;5;124m'\u001b[39m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#Defining the JSON file to store results for year\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     JSON_FILE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mtmdb_api_results_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mYEAR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m## Check if JSON_FILE exists\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tqdm_notebook' is not defined"
     ]
    }
   ],
   "source": [
    "# Start of OUTER loop\n",
    "for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0):\n",
    "    #Defining the JSON file to store results for year\n",
    "    JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "    ## Check if JSON_FILE exists\n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "    print(f'{JSON_FILE} status {file_exists}')\n",
    "    # If it does not exist: create it\n",
    "    if file_exists == False:\n",
    "    # save an empty dict with just \"imdb_id\" to the new json file.\n",
    "        with open(JSON_FILE,'w') as f:\n",
    "            json.dump([{'imdb_id':0}],f)\n",
    "    \n",
    "        #Saving new year as the current df\n",
    "        df = basics.loc[ basics['startYear']==YEAR].copy()\n",
    "        # saving movie ids to list\n",
    "        movie_ids = df['tconst'].copy()\n",
    "    \n",
    "        # Load existing data from json into a dataframe called \"previous_df\"\n",
    "        previous_df = pd.read_json(JSON_FILE)\n",
    "    \n",
    "        # filter out any ids that are already in the JSON_FILE\n",
    "        movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "    \n",
    "        #Get index and movie id from list\n",
    "        # INNER Loop\n",
    "        for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                                  desc=f'Movies from {YEAR}',\n",
    "                                  position=1,\n",
    "                                  leave=True):\n",
    "            try:\n",
    "                # Retrieve then data for the movie id\n",
    "                temp = get_movie_with_rating(movie_id)  \n",
    "                # Append/extend results to existing file using a pre-made function\n",
    "                write_json(temp,JSON_FILE)\n",
    "                # Short 20 ms sleep to prevent overwhelming server\n",
    "                time.sleep(0.02)\n",
    "            \n",
    "            except Exception as e:\n",
    "                errors.append([movie_id, e])\n",
    "    \n",
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\",\n",
    "                         compression=\"gzip\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
